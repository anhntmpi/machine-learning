{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/train.csv')\n",
    "data_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...        0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...        1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...        0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...        0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...        0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110435</td>\n",
       "      <td>0.803973</td>\n",
       "      <td>0.106075</td>\n",
       "      <td>0.473965</td>\n",
       "      <td>0.835617</td>\n",
       "      <td>0.106452</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.758175</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180128</td>\n",
       "      <td>0.621378</td>\n",
       "      <td>0.287144</td>\n",
       "      <td>0.503919</td>\n",
       "      <td>0.674919</td>\n",
       "      <td>0.403616</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.658812</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243421</td>\n",
       "      <td>0.640959</td>\n",
       "      <td>0.312765</td>\n",
       "      <td>0.279784</td>\n",
       "      <td>0.686775</td>\n",
       "      <td>0.280301</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.655752</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226978</td>\n",
       "      <td>0.776996</td>\n",
       "      <td>0.150657</td>\n",
       "      <td>0.336948</td>\n",
       "      <td>0.802121</td>\n",
       "      <td>0.125608</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484851</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561200</td>\n",
       "      <td>0.771463</td>\n",
       "      <td>0.244287</td>\n",
       "      <td>0.293096</td>\n",
       "      <td>0.717575</td>\n",
       "      <td>0.230842</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         D1        D2    D3   D4        D5        D6        D7        D8  \\\n",
       "0  0.366667  0.611765  0.05  0.0  0.110435  0.803973  0.106075  0.473965   \n",
       "1  0.100000  0.758175  0.30  0.0  0.180128  0.621378  0.287144  0.503919   \n",
       "2  0.100000  0.658812  0.10  0.0  0.243421  0.640959  0.312765  0.279784   \n",
       "3  0.100000  0.655752  0.10  0.0  0.226978  0.776996  0.150657  0.336948   \n",
       "4  0.000000  0.484851  0.00  0.0  0.561200  0.771463  0.244287  0.293096   \n",
       "\n",
       "         D9       D10  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.835617  0.106452  ...        1      1      1      1      0      1      0   \n",
       "1  0.674919  0.403616  ...        0      0      0      0      0      0      0   \n",
       "2  0.686775  0.280301  ...        0      0      0      0      0      0      0   \n",
       "3  0.802121  0.125608  ...        0      0      0      0      0      0      0   \n",
       "4  0.717575  0.230842  ...        0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      1      0  \n",
       "1      0      0      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1776 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>0.243144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>0.106480</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>0.352308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>0.208989</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>0.125177</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         D1        D2    D3   D4        D5        D6        D7        D8  \\\n",
       "0  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166  0.585445   \n",
       "1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105  0.411754   \n",
       "2  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453  0.517720   \n",
       "3  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606  0.288764   \n",
       "4  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361  0.303809   \n",
       "\n",
       "         D9       D10  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.743663  0.243144  ...        0      0      0      0      0      0      0   \n",
       "1  0.836582  0.106480  ...        1      1      1      1      0      1      0   \n",
       "2  0.679051  0.352308  ...        0      0      0      0      0      0      0   \n",
       "3  0.805110  0.208989  ...        0      0      0      0      0      0      0   \n",
       "4  0.812646  0.125177  ...        0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1776 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat((data_train.loc[:,'D1':'D1776'], data_test.loc[:,'D1':'D1776']))\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing:\n",
    "\n",
    "We're not going to do anything fancy here:\n",
    "\n",
    "    First I'll transform the skewed numeric features by taking log(feature + 1) - this will make the features more normal\n",
    "    Create Dummy variables for the categorical features\n",
    "    Replace the numeric missing values (NaN's) with the mean of their respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>D10</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "      <td>6252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.077505</td>\n",
       "      <td>0.593561</td>\n",
       "      <td>0.069026</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.214025</td>\n",
       "      <td>0.686696</td>\n",
       "      <td>0.273740</td>\n",
       "      <td>0.451342</td>\n",
       "      <td>0.748717</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026232</td>\n",
       "      <td>0.015035</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>0.021433</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.011676</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>0.010877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081249</td>\n",
       "      <td>0.106352</td>\n",
       "      <td>0.078285</td>\n",
       "      <td>0.111878</td>\n",
       "      <td>0.103234</td>\n",
       "      <td>0.079579</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>0.164758</td>\n",
       "      <td>0.072532</td>\n",
       "      <td>0.098037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159836</td>\n",
       "      <td>0.121703</td>\n",
       "      <td>0.119774</td>\n",
       "      <td>0.144835</td>\n",
       "      <td>0.113780</td>\n",
       "      <td>0.124225</td>\n",
       "      <td>0.107433</td>\n",
       "      <td>0.102973</td>\n",
       "      <td>0.136655</td>\n",
       "      <td>0.103730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.517811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139463</td>\n",
       "      <td>0.625580</td>\n",
       "      <td>0.205123</td>\n",
       "      <td>0.368555</td>\n",
       "      <td>0.706745</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.587055</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192214</td>\n",
       "      <td>0.673722</td>\n",
       "      <td>0.277716</td>\n",
       "      <td>0.497209</td>\n",
       "      <td>0.737381</td>\n",
       "      <td>0.283474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.671289</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263255</td>\n",
       "      <td>0.741290</td>\n",
       "      <td>0.334513</td>\n",
       "      <td>0.568045</td>\n",
       "      <td>0.788472</td>\n",
       "      <td>0.344877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                D1           D2           D3           D4           D5  \\\n",
       "count  6252.000000  6252.000000  6252.000000  6252.000000  6252.000000   \n",
       "mean      0.077505     0.593561     0.069026     0.037428     0.214025   \n",
       "std       0.081249     0.106352     0.078285     0.111878     0.103234   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.033300     0.517811     0.000000     0.000000     0.139463   \n",
       "50%       0.066700     0.587055     0.050000     0.000000     0.192214   \n",
       "75%       0.100000     0.671289     0.100000     0.000000     0.263255   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                D6           D7           D8           D9          D10  \\\n",
       "count  6252.000000  6252.000000  6252.000000  6252.000000  6252.000000   \n",
       "mean      0.686696     0.273740     0.451342     0.748717     0.270154   \n",
       "std       0.079579     0.091563     0.164758     0.072532     0.098037   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.625580     0.205123     0.368555     0.706745     0.192971   \n",
       "50%       0.673722     0.277716     0.497209     0.737381     0.283474   \n",
       "75%       0.741290     0.334513     0.568045     0.788472     0.344877   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          ...             D1767        D1768        D1769        D1770  \\\n",
       "count     ...       6252.000000  6252.000000  6252.000000  6252.000000   \n",
       "mean      ...          0.026232     0.015035     0.014555     0.021433   \n",
       "std       ...          0.159836     0.121703     0.119774     0.144835   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1771        D1772        D1773        D1774        D1775  \\\n",
       "count  6252.000000  6252.000000  6252.000000  6252.000000  6252.000000   \n",
       "mean      0.013116     0.015675     0.011676     0.010717     0.019034   \n",
       "std       0.113780     0.124225     0.107433     0.102973     0.136655   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1776  \n",
       "count  6252.000000  \n",
       "mean      0.010877  \n",
       "std       0.103730  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 1776 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_null = all_data.isnull().sum()\n",
    "\n",
    "ser_null[all_data.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ser_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r, c = all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.157152826277\n"
     ]
    }
   ],
   "source": [
    "stds = []\n",
    "\n",
    "for i in range(0, c):\n",
    "    stds.append(all_data.iloc[:,i].std())\n",
    "\n",
    "print (np.mean(stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D9', 'D10', 'D12', 'D13', 'D14', 'D15', 'D16', 'D17']\n"
     ]
    }
   ],
   "source": [
    "thresh_std = np.mean(stds)\n",
    "\n",
    "\n",
    "std_thresh = []\n",
    "\n",
    "for i in range(0, c):\n",
    "    if(all_data.iloc[:, i].std() < thresh_std):\n",
    "        std_thresh.append(all_data.columns[i])\n",
    "\n",
    "print(std_thresh[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe22ab70>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhSAiYsilEEREDLkUgoiIIff/ARJ7vHv96h/PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9ecac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data['D1'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D1136', 'D1137', 'D1134', 'D1135', 'D1132']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_std = list(set(list(all_data.columns)) - set(std_thresh))\n",
    "good_std[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe0aa668>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3fc4cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 564)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_corr = all_data[good_std].corr()\n",
    "matrix_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D203 and D195 = 0.90\n",
      "D1366 and D1385 = 0.89\n",
      "D1739 and D1565 = 0.88\n",
      "D1614 and D1470 = 0.88\n",
      "D177 and D659 = 0.88\n",
      "D1739 and D1596 = 0.88\n",
      "D1299 and D1337 = 0.88\n",
      "D194 and D104 = 0.87\n",
      "D969 and D196 = 0.87\n",
      "D1749 and D1565 = 0.87\n",
      "D1299 and D1412 = 0.87\n",
      "D1749 and D1744 = 0.87\n",
      "D204 and D196 = 0.86\n",
      "D1406 and D1266 = 0.86\n",
      "D1190 and D1096 = 0.86\n",
      "D1128 and D1096 = 0.86\n",
      "D1767 and D1602 = 0.86\n",
      "D83 and D659 = 0.86\n",
      "D1128 and D1190 = 0.86\n",
      "D1363 and D1285 = 0.86\n",
      "D1109 and D1128 = 0.85\n",
      "D1614 and D1602 = 0.85\n",
      "D1594 and D1690 = 0.85\n",
      "D1744 and D1614 = 0.85\n",
      "D1406 and D1337 = 0.84\n",
      "D1596 and D1690 = 0.84\n",
      "D1587 and D1764 = 0.83\n",
      "D1739 and D1614 = 0.83\n",
      "D1299 and D1397 = 0.83\n",
      "D1622 and D1587 = 0.83\n",
      "D200 and D196 = 0.82\n",
      "D1744 and D1565 = 0.82\n",
      "D1337 and D1412 = 0.82\n",
      "D969 and D204 = 0.82\n",
      "D1470 and D1602 = 0.82\n",
      "D1739 and D1749 = 0.82\n",
      "D1366 and D1232 = 0.82\n",
      "D1739 and D1690 = 0.82\n",
      "D1495 and D1605 = 0.82\n",
      "D1366 and D1299 = 0.81\n",
      "D1700 and D1470 = 0.81\n",
      "D1366 and D1337 = 0.81\n",
      "D1470 and D1767 = 0.81\n",
      "D1176 and D1159 = 0.81\n",
      "D1406 and D1397 = 0.81\n",
      "D1739 and D1543 = 0.81\n",
      "D1366 and D1376 = 0.81\n",
      "D1739 and D1764 = 0.81\n",
      "D1739 and D1744 = 0.81\n",
      "D1739 and D1622 = 0.81\n",
      "D1232 and D1385 = 0.81\n",
      "D1744 and D1469 = 0.81\n",
      "D1749 and D1470 = 0.81\n",
      "D1315 and D1385 = 0.80\n",
      "D1406 and D1299 = 0.80\n",
      "D1614 and D1469 = 0.80\n",
      "D1733 and D1690 = 0.80\n",
      "D1622 and D1470 = 0.80\n",
      "D1744 and D1767 = 0.80\n",
      "D1315 and D1366 = 0.80\n",
      "D1109 and D1096 = 0.80\n",
      "D1511 and D1744 = 0.80\n"
     ]
    }
   ],
   "source": [
    "n_feat = matrix_corr.shape[0]\n",
    "\n",
    "thresh_corr = 0.8\n",
    "\n",
    "# List of pairs along with correlation above threshold\n",
    "corr_list = []\n",
    "\n",
    "#Search for the highly correlated pairs\n",
    "for i in range(0,n_feat): #for 'size' features\n",
    "    for j in range(i+1,n_feat): #avoid repetition\n",
    "        if (matrix_corr.iloc[i,j] >= thresh_corr and matrix_corr.iloc[i,j] < 1) or (matrix_corr.iloc[i,j] < 0 and matrix_corr.iloc[i,j] <= -thresh_corr):\n",
    "            corr_list.append([matrix_corr.iloc[i,j],i,j]) #store correlation and columns index\n",
    "\n",
    "#Sort to show higher ones first            \n",
    "s_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n",
    "\n",
    "#Print correlations and column names\n",
    "for v,i,j in s_corr_list:\n",
    "    print (\"%s and %s = %.2f\" % (good_std[i],good_std[j],v))            \n",
    "\n",
    "# Strong correlation is observed between the following pairs\n",
    "# This represents an opportunity to reduce the feature set through transformations such as PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 62)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_std), len(s_corr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6252L, 564L), (3751L,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = all_data[good_std].values\n",
    "y = data_train['Activity'].values\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6252L, 502L)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=502)\n",
    "pca.fit(x)\n",
    "x_pca = pca.transform(x)\n",
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2513L, 502L), (2513L,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_pca[:data_train.shape[0]]\n",
    "x_test = x_pca[data_train.shape[0]:]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train_train, x_train_val, y_train_train, y_train_val = train_test_split(x_train, y, test_size=0.33, random_state=42)\n",
    "\n",
    "x_train_train.shape, y_train_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "names = [\"Nearest Neighbors\", \n",
    "         \"Linear SVM\", \n",
    "         \"RBF SVM\",\n",
    "         \"Decision Tree\",\n",
    "         \"Random Forest\",\n",
    "         \"AdaBoost\",\n",
    "         \"Naive Bayes\",\n",
    "         \"QDA\"]\n",
    " \n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.641\n",
      "---------------------------\n",
      "QDA accuracy: 0.713\n",
      "---------------------------\n",
      "Naive Bayes accuracy: 0.527\n",
      "---------------------------\n",
      "Linear SVM accuracy: 0.772\n",
      "---------------------------\n",
      "RBF SVM accuracy: 0.578\n",
      "---------------------------\n",
      "AdaBoost accuracy: 0.705\n",
      "---------------------------\n",
      "Random Forest accuracy: 0.640\n",
      "---------------------------\n",
      "Nearest Neighbors accuracy: 0.734\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(x_train_train, y_train_train)\n",
    "    scores[name] = clf.score(x_train_val, y_train_val)\n",
    "\n",
    "sorted(scores.items(), key=itemgetter(1))\n",
    "\n",
    "for name in scores:\n",
    "    print name + \" accuracy: %0.3f\" % scores[name]\n",
    "    print \"---------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, Linear SVM accuracy has the best score. Now we find the best estimators for Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "\n",
    "parameter_grid = {'C': [0.025, 0.5, 1],\n",
    "                  'probability': [True],\n",
    "                  'kernel': ['linear', 'poly', 'rbf']}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=parameter_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = grid_search.fit(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.025, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77221324717285944"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best = SVC(C=0.025, kernel='linear', probability=True)\n",
    "clf_best.fit(x_train_train, y_train_train)\n",
    "clf_best.score(x_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13011334,  0.86988666],\n",
       "       [ 0.82784182,  0.17215818],\n",
       "       [ 0.19264617,  0.80735383],\n",
       "       [ 0.79265269,  0.20734731]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = clf_best.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25190181,  0.74809819],\n",
       "       [ 0.13011334,  0.86988666],\n",
       "       [ 0.82784182,  0.17215818],\n",
       "       [ 0.19264617,  0.80735383],\n",
       "       [ 0.79265269,  0.20734731]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.25190181,  0.13011334,  0.82784182,  0.19264617,  0.79265269]),\n",
       " 2501)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5, 0], len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=('MoleculeId', 'PredictedProbability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MoleculeId</th>\n",
       "      <th>PredictedProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.251902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.130113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.827842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.192646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.792653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MoleculeId  PredictedProbability\n",
       "0           1              0.251902\n",
       "1           2              0.130113\n",
       "2           3              0.827842\n",
       "3           4              0.192646\n",
       "4           5              0.792653"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['MoleculeId'] = range(1, len(y_test)+1)\n",
    "result_df['PredictedProbability'] = y_test[:, 0]\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"Bio-Response-SVM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
